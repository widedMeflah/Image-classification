{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## **Meflah wided _22214601**"],"metadata":{"id":"jR-aKcSIxRYp"}},{"cell_type":"markdown","source":["# Notebook GAN\n","\n","Dans ce notebook, nous allons mis en place un GAN dans le but de générer des images"],"metadata":{"id":"7ot1Xm-ExdsJ"}},{"cell_type":"markdown","source":["# **NB :** Par erreur, j'ai perdu les résultats. Cependant, j'avais déjà conservé ce notebook avec les résultats au format PDF précédemment. Je joins à ce notebook sa version PDF complète. Je m'excuse pour cela."],"metadata":{"id":"Jie1xe6P4mEL"}},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"GyJfp8-VJtoX"}},{"cell_type":"code","source":["# utiliser cette cellule pour installer les librairies manquantes\n","# pour cela il suffit de taper dans cette cellule : !pip install nom_librairie_manquante\n","# d'exécuter la cellule et de relancer la cellule suivante pour voir si tout se passe bien\n","# recommencer tant que toutes les librairies ne sont pas installées ..."],"metadata":{"id":"GO7owGQDJu7c","executionInfo":{"status":"ok","timestamp":1702549891626,"user_tz":-60,"elapsed":14,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Importation des différentes librairies utiles pour le notebook\n","\n","# Tensorboard\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","\n","# Clear any logs from previous runs\n","!rm -rf ./logs/\n","\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","#Sickit learn met régulièrement à jour des versions et\n","#indique des futurs warnings.\n","#ces deux lignes permettent de ne pas les afficher.\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)\n","\n","# librairies générales\n","import pickle\n","import pandas as pd\n","#from scipy.stats import randint\n","import numpy as np\n","import string\n","import time\n","import base64\n","import re\n","import sys\n","import copy\n","import random\n","from numpy import mean\n","from numpy import vstack\n","from numpy import std\n","from numpy import ones\n","from numpy import zeros\n","from numpy.random import randint\n","\n","\n","# librairie affichage\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from PIL import Image\n","import plotly.graph_objs as go\n","import plotly.offline as py\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.manifold import TSNE\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","\n","# TensorFlow et keras\n","import tensorflow as tf\n","from keras import layers\n","from keras import models\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import img_to_array, load_img\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.preprocessing import image\n","from tqdm import tqdm\n","from keras.models import load_model\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from keras.datasets import fashion_mnist\n","from tensorflow.keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import Conv2DTranspose\n","from keras.layers import MaxPooling2D\n","from keras.layers import BatchNormalization\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Conv2DTranspose\n","from keras.layers import LeakyReLU\n","from keras.layers import Reshape\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.optimizers import Adam\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","import cv2\n","import glob\n","from numpy import expand_dims\n","import matplotlib.pyplot as plt"],"metadata":{"id":"WWBr8C3wLlll","executionInfo":{"status":"ok","timestamp":1702549897320,"user_tz":-60,"elapsed":5706,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# pour monter son drive Google Drive local\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"WK-phCWFLmI1","outputId":"5580beec-7327-430d-cada-eb2439f6effc","executionInfo":{"status":"error","timestamp":1702549922503,"user_tz":-60,"elapsed":25210,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":3,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-95d6df15acda>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# pour monter son drive Google Drive local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     case = d.expect([\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    355\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mincoming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_nonblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayafterread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mincoming\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Keep reading until exception or return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import sys\n","my_local_drive='/content/gdrive/MyDrive/ML2_prjt2023'\n","# Ajout du path pour les librairies, fonctions et données\n","sys.path.append(my_local_drive)\n","# Se positionner sur le répertoire associé\n","%cd $my_local_drive\n","\n","%pwd"],"metadata":{"id":"2ibLMr23L2r2","executionInfo":{"status":"aborted","timestamp":1702549922506,"user_tz":-60,"elapsed":31,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IMG_SIZE=124\n","COLUMNS = 25 # Nombre d'images à afficher\n","\n","#Donne une liste d'images à la bonne dimension avec leur classe\n","def create_training_data(path_data, list_classes):\n","  training_data=[]\n","  for classes in list_classes:\n","      path=os.path.join(path_data, classes)\n","      class_num=list_classes.index(classes)\n","      for img in os.listdir(path):\n","        try:\n","          img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)\n","          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n","          #new_array = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n","          training_data.append([new_array, class_num])\n","        except Exception as e:\n","          pass\n","  return training_data\n","\n","def create_X_y (path_data, list_classes):\n","  # récupération des données\n","  training_data=create_training_data(path_data, list_classes)\n","  # tri des données\n","  random.shuffle(training_data)\n","  # création de X et y\n","  X=[]\n","  y=[]\n","  for features, label in training_data:\n","    X.append(features)\n","    y.append(label)\n","  X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 3)\n","  y=np.array(y)\n","  return X,y\n","\n","\n","# Chargement des données\n","def load_data():\n","  my_path=\"Data_Project/Tiger-Fox-Elephant/\"\n","  #my_path=\"./\"\n","  my_classes=['fox']\n","  X,y=create_X_y (my_path,my_classes)\n","\n","  # Ajout d'une dimension pour le canal (1) !! pas besoin de l'ajouter il y est déjà\n","  #Xi = expand_dims(X_train, axis=-1)\n","  # Normalisation\n","  Xi = X.astype('float32')\n","  # scale from [0,255] to [0,1]\n","  Xi = Xi / 255.0\n","  return Xi\n","\n","def plot_examples(X):\n","  plt.figure(figsize=(60,60))\n","  for i in range(COLUMNS):\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    # cv2 lit met les images en BGR et matplotlib lit du RGB\n","    # X[i] = cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB)\n","    plt.imshow(X[i, :, :])"],"metadata":{"id":"KJmg7uj8G7C0","executionInfo":{"status":"aborted","timestamp":1702549922508,"user_tz":-60,"elapsed":33,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_generator(latent_dim=100):\n","  model = Sequential()\n","    # 1/4 de l'image (7x7) * nombre d'images possibles\n","  n_nodes = 100 * 31 * 31\n","  model.add(Dense(n_nodes, input_dim=latent_dim))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Reshape((31, 31, 100)))\n","  # upsample to 14x14\n","  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.2))\n","  # upsample to 28x28\n","  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(Conv2D(3, (7,7), activation='sigmoid', padding='same'))\n","  opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","  return model"],"metadata":{"id":"hxbNmxdl97xw","executionInfo":{"status":"aborted","timestamp":1702549922512,"user_tz":-60,"elapsed":37,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La définition de la partie du générateur est :        "],"metadata":{"id":"0Gvzy3-6rde-"}},{"cell_type":"code","source":["generator_model=create_generator()\n","generator_model.summary()"],"metadata":{"id":"tM3vrT40rmC5","executionInfo":{"status":"aborted","timestamp":1702549922514,"user_tz":-60,"elapsed":39,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nous pouvons tester le générateur pour voir un exemple d'image générée :     "],"metadata":{"id":"K3LjJHqmaRtL"}},{"cell_type":"code","source":["latent_dim=100\n","generator = create_generator()\n","noise=tf.random.normal([1,latent_dim])\n","generated_image = generator (noise, training=False)\n","plt.imshow (generated_image[0, :, :, 0])\n"],"metadata":{"id":"-T_WPQe5YjNB","executionInfo":{"status":"aborted","timestamp":1702549922516,"user_tz":-60,"elapsed":40,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_discriminator():\n","  model_fox = Sequential()\n","  # Convolution and pooling\n","  model_fox.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name=\"Conv2D_1\", padding=\"same\", strides=1))\n","  model_fox.add(tf.keras.layers.BatchNormalization(axis=-1))\n","  model_fox.add(MaxPooling2D(pool_size=(2, 2), name=\"Maxpooling2D_1\"))\n","  model_fox.add(Dropout(0.3))\n","\n","  # Convolution and pooling\n","  #model_fox.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name=\"Conv2D_2\", padding=\"same\", strides=1))\n","  #model_fox.add(tf.keras.layers.BatchNormalization(axis=-1))\n","  #model_fox.add(MaxPooling2D(pool_size=(2, 2), name=\"Maxpooling2D_2\"))\n","  #model_fox.add(Dropout(0.3))\n","\n","  # flatten\n","  model_fox.add(Flatten(name=\"flatten\") )\n","\n","  # Partie classification\n","  model_fox.add(Dense(512, activation='relu'))\n","  model_fox.add(Dense(1, activation='sigmoid'))\n","\n","  #model_fox.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","  model_fox.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='binary_crossentropy',metrics=['accuracy'])\n","\n","  return model_fox\n","\n","# def create_discriminator():\n","#   model = Sequential()\n","#   model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=[124,124,3]))\n","#   model.add(LeakyReLU(alpha=0.2))\n","#   model.add(Dropout(0.3))\n","#   model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n","#   model.add(LeakyReLU(alpha=0.2))\n","#   model.add(Dropout(0.3))\n","#   model.add(Flatten())\n","#   model.add(Dense(1, activation='sigmoid'))\n","#   opt = Adam(learning_rate=0.0002, beta_1=0.5)\n","#   model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","#   return model"],"metadata":{"id":"yCWEZBu7bB9J","executionInfo":{"status":"aborted","timestamp":1702549922521,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Le modèle pour le discriminateur est :       "],"metadata":{"id":"i3JMnDQjrCVP"}},{"cell_type":"code","source":["model_discriminator=create_discriminator()\n","model_discriminator.summary()"],"metadata":{"id":"iM4Zmbm7rNUt","executionInfo":{"status":"aborted","timestamp":1702549922524,"user_tz":-60,"elapsed":47,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["discriminator=create_discriminator()\n","prediction=discriminator(generated_image)\n","print (prediction)"],"metadata":{"id":"BLltp5PXhFNF","executionInfo":{"status":"aborted","timestamp":1702549922525,"user_tz":-60,"elapsed":48,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creation d'un jeu de données de vraies images\n","# les vraies images sont labélisées avec 1\n","def generate_real_samples(dataset, nb_images):\n","\t# tirage aléatoire\n","\txi = randint(0, dataset.shape[0], nb_images)\n","\t# sélection des images\n","\tX = dataset[xi]\n","\t# mettre 1 comme label de classe\n","\ty = ones((nb_images, 1))\n","\treturn X, y\n","\n","# Création d'un faux jeu de données\n","# elles seront labélisées avec 0\n","def generate_fake_samples(nb_images):\n","  # generation de nombres aléatoires entre 0 et 1\n","  # attention ici on simplifie en mettant la taille de l'image\n","  # normalement il faut prendre latent_dim\n","  X = np.random.rand(124 * 124 * nb_images * 3)\n","  # reshape en images grises (couleur !!!)\n","  X = X.reshape((nb_images, 124, 124, 3))\n","  # mettre 0 comme label de classe\n","  y = zeros((nb_images, 1))\n","  return X, y"],"metadata":{"id":"iEcxTuMnbtpj","executionInfo":{"status":"aborted","timestamp":1702549922525,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train the discriminator model\n","def train_discriminator(model, dataset, epochs=100, batchsize=256):\n","  # on constitue un jeu de données de batchsize/2 images réelles et images fausses\n","\thalf_batch = int(batchsize / 2)\n","\t# boucler sur les epochs\n","\tfor i in range(epochs):\n","\t\t# sélection d'images réelles\n","\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n","\t\t# mettre à jour le discriminateur avec les images réelles\n","\t\t_, real_acc = model.train_on_batch(X_real, y_real)\n","\t\t# generation de fausses images\n","\t\tX_fake, y_fake = generate_fake_samples(half_batch)\n","\t\t# mise à jour du discriminateur avec de fausses images\n","\t\t_, fake_acc = model.train_on_batch(X_fake, y_fake)\n","\t\t# Affichage des résultats pour l'accuracy des vraies et des fausses\n","\t\tprint('>%d accuracy_real=%.0f%% accuracy_fake=%.0f%%' % (i+1, real_acc*100, fake_acc*100))"],"metadata":{"id":"Wm_ITGORfHqP","executionInfo":{"status":"aborted","timestamp":1702549922526,"user_tz":-60,"elapsed":46,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pwd\n","\n","nb_images_total=256 # 128 images de chaque classe\n","epochs=50\n","\n","# chargement du modèle\n","model = create_discriminator()\n","\n","# chargement des données\n","dataset=load_data()\n","\n","# lancement de l'entrainement du discriminateur\n","train_discriminator(model, dataset, epochs, nb_images_total)"],"metadata":{"id":"zXimkMRSf62K","executionInfo":{"status":"aborted","timestamp":1702549922526,"user_tz":-60,"elapsed":44,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_gan(generator_model, discriminator_model):\n","  # mettre les poids du discriminateur non entrable\n","  discriminator_model.trainable = False\n","  # un seul modele qui regroupe\n","  model = Sequential()\n","  # ajout du générateur\n","  model.add(generator_model)\n","  # ajout du discriminateur\n","  model.add(discriminator_model)\n","\n","  opt = Adam(learning_rate=0.0003, beta_1=0.5)\n","  model.compile(loss='binary_crossentropy', optimizer=opt)\n","  return model"],"metadata":{"id":"FhdlTkisl9wY","executionInfo":{"status":"aborted","timestamp":1702549922527,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Le modèle GAN final ressemble à ceci :"],"metadata":{"id":"gsvgFVWstDHW"}},{"cell_type":"code","source":["latent_dim = 100\n","\n","# creation du générateur\n","generator_model = create_generator(latent_dim)\n","# creation du discriminateur\n","discriminator_model = create_discriminator()\n","\n","# creation du gan\n","gan_model = create_gan(generator_model, discriminator_model)\n","\n","gan_model.summary()\n","\n"],"metadata":{"id":"w8nqyBkUtEDN","executionInfo":{"status":"aborted","timestamp":1702549922528,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_latent_points (latent_dim, nb_images):\n","  X_input = np.random.randn(latent_dim * nb_images)\n","  X_input = X_input.reshape(nb_images, latent_dim)\n","  return X_input\n","\n","def generate_fake_samples_for_generator(generator_model, latent_dim, nb_images):\n","  # generation des points\n","  X_input = generate_latent_points (latent_dim,nb_images)\n","  # prediction de la sortie du générateur\n","  X = generator_model.predict(X_input)\n","  # A ce niveau on considère que les images sont fausses\n","  # donc on met 0 comme label.\n","  y = zeros((nb_images, 1))\n","  return X, y\n","\n","def plot_and_save_generatedimages(generated_images, epoch, nb_images=10):\n","\t# Affichage des images\n","\tfor i in range(nb_images * nb_images):\n","\t\tplt.subplot(nb_images, nb_images, 1 + i)\n","\t\tplt.axis('off')\n","\t\tplt.imshow(generated_images[i, :, :])\n","\t# sauvegarde de l'image\n","\tfilename = 'generated_plot_Fox_withGan%03d.png' % (epoch+1)\n","\tplt.savefig(filename)\n","\tplt.close()\n","\n","\n","\n","def evaluate_model (dataset, epoch, generator_model, discriminator_model, latent_dim, nb_images=100, save_model=True):\n","  # récupération de vraies images pour le discriminateur\n","  X_real, y_real = generate_real_samples(dataset, nb_images)\n","  # Evaluation de l'accuracy pour le discriminateur\n","  _, acc_real = discriminator_model.evaluate(X_real, y_real, verbose=0)\n","\n","  # génération de fausses images pour le générateur et donc le gan\n","  X_fake, y_fake = generate_fake_samples_for_generator(generator_model, latent_dim, nb_images)\n","  # Evaluation du discriminateur avec des fausses images\n","  _, acc_fake = discriminator_model.evaluate(X_fake, y_fake, verbose=0)\n","\n","  print ('Accuracy reélle : %.0f%%, fausse : %.0f%%' % (acc_real*100, acc_fake*100))\n","\n","  plot_and_save_generatedimages(X_fake, epoch)\n","  if save_model==True:\n","    # sauvegarde du generateur pour un autre usage\n","    filename = 'generator_model_Fox%03d.h5' % (epoch + 1)\n","    generator_model.save(filename)\n","\n","\n"],"metadata":{"id":"uMpAj9agDePI","executionInfo":{"status":"aborted","timestamp":1702549922528,"user_tz":-60,"elapsed":43,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train the generator and discriminator\n","def train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs=100, batchsize=256):\n","  print(\"Dataset shape : \", dataset.shape)\n","  # Pour déterminer combien il y aura de batchs analysés à chaque epoch\n","  batches_per_epoch = int(dataset.shape[0] / batchsize)\n","  print(\"Batches_per_epoch : \", batches_per_epoch)\n","\n","  # checkpoint_generator = tf.train.Checkpoint(generator_model)\n","  # checkpoint_discriminator = tf.train.Checkpoint(discriminator_model)\n","  # checkpoint_gan = tf.train.Checkpoint(gan_model)\n","\n","  # pour récupérer le même nombre d'images fausses et vraies\n","  half_batch = int(batchsize / 2)\n","\n","  for i in range(epochs):\n","    # parcours des batches pour chaque pas d'epoch\n","    for j in range(batches_per_epoch):\n","      # PARTIE DISCRIMINATOR\n","      #tirage aléatoire de half_batch images vraies\n","      X_real, y_real = generate_real_samples(dataset, half_batch)\n","      # generation de half_size fausses images\n","      X_fake, y_fake = generate_fake_samples_for_generator(generator_model, latent_dim, half_batch)\n","      # vstack permet de concaténer les vraies et fausses images dans X (resp. dans y)\n","      # on aurait pu utiliser np.concatenate (np.concatenate([X_real, X_fake]))\n","      X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n","\n","      # la ligne suivante permet au discriminateur de mettre à jour ses poids\n","      # attention dans le GAN il ne peut pas aprendre donc il ne peut le faire qu'ici\n","      discriminator_loss,_  = discriminator_model.train_on_batch(X, y)\n","\n","      # PARTIE GENERATOR ET DONC DE L'ENTREE DU GAN\n","      # Création des points comme entrée du générateur\n","      #\n","      X_for_gan = generate_latent_points(latent_dim, batchsize)\n","      # On met un 1 pour les labels des fausses images pour faire croire au discriminateur\n","      # qu'il s'agit de vraies images\n","      y_for_gan = ones((batchsize, 1))\n","\n","      # mise à jour des poids du générateur par propagation de l'esseur\n","      # du discriminateur\n","      gan_loss = gan_model.train_on_batch(X_for_gan, y_for_gan)\n","\t\t\t# Affichage des loss\n","      print('epoch %d - batch %d/%d, discriminator_loss=%.3f, generator_loss=%.3f'%(i+1, j+1, batches_per_epoch, discriminator_loss, gan_loss))\n","\n","    # Toutes les 20 epochs evaluation du modèle et sauvegarde du générateur\n","    if i==1 or i % 20==0:\n","        evaluate_model (dataset, i, generator_model, discriminator_model, latent_dim, save_model=False)\n","\n","    if i==1 or i % 250==0:\n","        #Save checkpoints every 20 iterations\n","        evaluate_model (dataset, i, generator_model, discriminator_model, latent_dim)\n","        # save_path = checkpoint_generator.save('/training_checkpoints_gan/generator')\n","        # save_path = checkpoint_discriminator.save('/training_checkpoints_gan/discriminator')\n","        # save_path = checkpoint_gan.save('/training_checkpoints_gan/gan')"],"metadata":{"id":"XssqYHYas83D","executionInfo":{"status":"aborted","timestamp":1702549922529,"user_tz":-60,"elapsed":44,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_dim = 100\n","epochs=1000\n","batchsize=128\n","# Creation du discriminateur\n","discrimator_model = create_discriminator()\n","# Creation du generateur\n","generator_model = create_generator(latent_dim)\n","# Creation du GAN\n","gan_model = create_gan(generator_model, discriminator_model)\n","# Chargement des données\n","dataset = load_data()\n"],"metadata":{"id":"4DPeZBLpat6q","executionInfo":{"status":"aborted","timestamp":1702549922529,"user_tz":-60,"elapsed":44,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model\n","# Avec batchsize 25, epochs 1000\n","# model = train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs,batchsize)\n","#print(dataset.shape)"],"metadata":{"id":"XVgZrQGQTbBH","executionInfo":{"status":"aborted","timestamp":1702549922531,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model\n","# Avec batchsize 10, epochs 1000\n","# model = train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs,batchsize)\n","#print(dataset.shape)"],"metadata":{"id":"mkTDi0uJiddq","executionInfo":{"status":"aborted","timestamp":1702549922531,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train model\n","# Avec batchsize 512, epochs 1000\n","epochs=2500\n","batchsize=32\n","model = train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs,batchsize)\n","#print(dataset.shape)"],"metadata":{"id":"_0ncFa1C42Q3","executionInfo":{"status":"aborted","timestamp":1702549922531,"user_tz":-60,"elapsed":45,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs=3000\n","batchsize=10\n","model = train(generator_model, discriminator_model, gan_model, dataset, latent_dim, epochs,batchsize)"],"metadata":{"id":"LjgBU-mwt5Xn","executionInfo":{"status":"aborted","timestamp":1702549922532,"user_tz":-60,"elapsed":46,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model = load_model('modeleFoxAmelioreIDG.h5')"],"metadata":{"id":"sQv4-wkU7Jkr","executionInfo":{"status":"aborted","timestamp":1702549922535,"user_tz":-60,"elapsed":49,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Création d'un vecteur aléatoire de taille latent_dim\n","latent_points = generate_latent_points(100, 1)"],"metadata":{"id":"hYSbs58S7--a","executionInfo":{"status":"aborted","timestamp":1702549922539,"user_tz":-60,"elapsed":53,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent_points = generate_latent_points(100, 1)\n","generated_image = generator_model.predict(latent_points)\n","print(generated_image.shape)\n","plt.imshow(generated_image[0, :, :])"],"metadata":{"id":"VEq4iFDR8Wxr","executionInfo":{"status":"aborted","timestamp":1702549922541,"user_tz":-60,"elapsed":54,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow (generated_image[0, :, :, 0], cmap=plt.cm.binary)"],"metadata":{"id":"93fxCTQe8pLD","executionInfo":{"status":"aborted","timestamp":1702549922541,"user_tz":-60,"elapsed":54,"user":{"displayName":"Wided MEFLAH","userId":"14621791054567712020"}}},"execution_count":null,"outputs":[]}]}